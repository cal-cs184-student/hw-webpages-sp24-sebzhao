<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Charlie Shou and Sebastian Zhao</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="TODO">https://cal-cs184-student.github.io/hw-webpages-sp24-sebzhao/hw3/index.html</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div>

<h2 align="middle">Overview</h2>
<p>
    For this project, we created an image renderer that uses pathtracing algorithms to create more realistic images based off of the material and reflectance of materials. The first part focused on generating rays from an image space, generating samples from an image space, and detecting intersections for triangles and spheres. The second part implemented a bounding volume hierarchy in order to accelerate how fast we are able to perform our renders by creating bounding boxes for our primatives.

    In part 3, we added direct lighting through one-bounce illumination and in two different ways--through sampling hemispheres uniformly and the light source directly. In part four, we added global lighting through n-bounce lighting and also unbiased the estimate using Russian Roulette. In part five, we implemented adaptive sampling for efficiency, allowing us to sample less areas that we are already confident about.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
    The first task for this part required me to first translate coordinates from the image space into a ray in the world space. To do this, I created reference points for the bottom left and top right corners of the camera space that correspond to the normalized image space given the hFov and vFov. After this, I calculated where the coordinate would be in the camera space by taking (top right - bottom left) * image coordinates + bottom left. With the camera space coordinates, I simply used the c2w matrix to transform the coordinates into world coordinates, which I could then normalize and use for the direction vector of the ray. In order to implement the primitive intersection parts, I calculated the t value where an intersection would be with the given algorithms from lecture. If the t value fell within the min and max t, I would count that as an intersection and update the isect object accordingly. Otherwise, there was no intersection.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    In order to implement triangle intersection, I implemented the Moller Trumbore algorithm that we learned in class. This involved calculating the barycentric coordinates of where the intersection would be in the triangle in question. If the two barycentric coordinates summed up to be less than 1, then we know there is an intersection because the third coordinate would have to lie between [0, 1]. Using the derived t, we can check if it is between min t and max t and count it as an intersection if it is. We then would use the barycentric coordinates to calculate the vertex normal and update the isect and ray appropriately.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBgems.png" align="middle" width="400px"/>
        <figcaption>CBgems.dae</figcaption>
      </td>
      <td>
        <img src="images/CBcoil.png" align="middle" width="400px"/>
        <figcaption>CBcoil.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/CBdragon.png" align="middle" width="400px"/>
        <figcaption>CBdragon.dae</figcaption>
      </td>
      <td>
        <img src="images/teapot.png" align="middle" width="400px"/>
        <figcaption>teapot.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    To construct my BVH, I used a recursive algorithm that split the primitives in the left and right branches of the tree. I started by expanding the bounding box of the current node to accomadate all current primatives, which is useful to determine if there is any intersection in the first place. If the number of primitives happens to be small enough, I would create a leaf node. Otherwise, I would split by the widest axis using the average values of the centroids at that axis. This would be recursively passed to the left and right subtrees. If we hit a case where all primitives are split onto one side of the tree, we treat it as a leaf node to prevent infinite recursive calls.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/walle.png" align="middle" width="400px"/>
        <figcaption>walle.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/peter.png" align="middle" width="400px"/>
        <figcaption>peter.dae</figcaption>
      </td>
      <td>
        <img src="images/beast.png" align="middle" width="400px"/>
        <figcaption>beast.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    For moderately large scenes like CBdragon, there was a significant different in the performance between BVH accelerated rendering and non accelerated rendering. For the CBdragon image without BVH, it took 96 seconds to render the entire image at 0.0041 million rays per second. In contrast, using BVH sped up rendering to be just 0.1020 seconds at 4.4631 million rays per second. The entire process to build out the BVH tree took just 0.1143 seconds as well, so it was well worth the boost in speed that it provided.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    For uniform hemisphere sampling, we take N samples, through the hemisphere sampler which should sample uniformly across the hemisphere. We construct a ray using the sampled vector in the object space and if it intersects with any object, we add the light emission times constants, namely the BSDF, cos theta (which is just the z normal vector as the object plane's normal vector points upwards in the z direction), and divide the probability which is 1/2pi. This value is accumulated as a sum and then divided by the number of samples to get the Monte Carlo estimate.
    For importance sampling, we iterate over all of the lights and use the sample_L function to sample an incoming direction as well as figure out the distance of the light to the intersection and the pdf of the sample. We convert our world space direction to object space and then similarly calculate the radiance as in the above. Finally, we divide by the ns_area_light in order to get the Monte Carlo estimate.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/CBbunny_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny</figcaption>
      </td>
      <td>
        <img src="images/spheres_H_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/bunny_64_32.png" align="middle" width="400px"/>
        <figcaption>CBbunny</figcaption>
      </td>
      <td>
        <img src="images/spheres_64_32.png" align="middle" width="400px"/>
        <figcaption>CBspheres</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/spheres_64_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/spheres_64_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/spheres_64_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/spheres_64_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    As the number of light rays increase, the amount of noise in soft shadows decreases. This makes sense as we have a better idea of the shadows with a higher amount of samples. Although there is still quite a bit of noise, in the l=64 case, we start to see a pretty smooth shadow on the top.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    It seems that lighting sampling is much more efficient than uniform hemisphere sampling, as it only samples locations where the ray can possibly intersect with a light source. This means that with the same hyperparameters, there will be less overall noise and more overall clarity in the same picture despite the same amount of camera rays and samples per pixel. In the examples shown above, there are relatively high quality results with a small amount of samples per pixel using importance sampling on light sources, whereas you need a lot of samples per pixel for the hemisphere sampling. However, both can create good results, it's just a matter of scaling factors.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    First, I wrote the code with the assumption that the light is accumulated instead of only returning the nth bounce. I followed the pseudocode to add in the one_bounce radiance and then to find a new direction and add the contribution of the first surface it intersects with. I used sample_f in order to sample this direction, and then decreased the depth of the array to allow for recursion. If it intersected with an object, then I would add to the total light the recursive at_least_one_bounce_radiance light scaled by the factors of bsdf, cos theta (z component), and divided by the pdf. I separately solved the problem for returning the nth bounce, by returning only the one_bounce_radiance in the base case, and not adding the one_bounce_radiance by default otherwise.
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/spheres.png" align="middle" width="400px"/>
        <figcaption>spheres</figcaption>
      </td>
      <td>
        <img src="images/bunny.png" align="middle" width="400px"/>
        <figcaption>bunny</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/only_direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/only_indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Direct illumination is very dramatic and bright, with minimal softness. It looks like more early animation, and lacks realism. on the other hand, indirect illumination lacks the actual bright spots and direct light sources, but does have the softness and realism that when put together makes the image look more realistic.
</p>
<br>




<h3>
  For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag), and isAccumBounces=false. Explain in your writeup what you see for the 2nd and 3rd bounce of light, and how it contributes to the quality of the rendered image compared to rasterization. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_m_0_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_1_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_2_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_3_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_4_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_5_bounce.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>

  </table>
</div>
<br>
<p>
    In the 2nd and 3rd bounce, we start to see some of the colors bleeding, so that there is actually blue and red light reflected onto the bunny and the floor/walls. Additionally, we start to see more of the actual shape of the bunny. Compared to rasterization, the form is also visible through shadows and lighting. This adds an extra sense of realism and quality to the overall rendered image as the lighting effects are realistic whereas although you can map textures and also lights onto rasterized images, they might not have the bleeding color effect or the correct shadows.
</p>
<br>



<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4, and 5(the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_m_0_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_1_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_2_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_3_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_4_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_5_full.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    The 0th and 1st (m) pictures are either only the direct light source or a very harsh lighting outline of the bunny and walls. They look flat and not realistic. Once you get to 2 or 3, there is effectively a pretty realistic rendering wherein you can start to see the figure more defined, as well as lighting effects where you can see the blue and red glow on the bunny as a result of light rays reflecting off the walls.
</p>
<br>



<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_m_0_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_1_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_2_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_3_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_m_4_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_m_100_rr.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Again, the realism/quality of the image is mostly there after you get to ray_depth 2 or 3. For the m=100, you can see that some shadows are more defined and small details like being rendered in higher quality, but less dramatic of a difference compared to small m to larger m. I can't tell if the image is less biased since m is higher, but it does look higher quality compared to 2 or 3.
</p>
<br>


<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_1.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 1 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_2.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 2 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_4.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_8.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 8 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_16.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 16 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_64.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 64 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_1024.png" align="middle" width="400px"/>
        <figcaption>sample_rate = 1024 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    With only 1 sample, the image tends to be very blurry and with a lot of noise, missing most of the detail. As you increase the number of samples, the quality increases and the amount of noise decreases, and the noise is pretty much not visible at a sampling rate of 64, although there are slight traces of noise. At the highest sampling rate 1024, no noise is perceivable at all and the quality of the image is much higher.
</p>
<br>








<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling is just the idea that certain regions of the image will converge quicker than others. We are effectively calculating the 95% confidence interval of the illuminance and trying to make sure that the interval is small. We want to have a low variance or high number of samples so that the average is likely to be close to the true value, so once we reach a certain level of confidence, we stop sampling from that area. Implementation wise, I simply just followed the pseudocode and calculated the mean, std, and plugged into our derived formula, but only calculated this every batch_size samples. If I was low enough, we terminated the iteration early and returned the average of the samples as well as updating the count of samples.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny.png" align="middle" width="400px"/>
        <figcaption>Rendered image (bunny)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (bunny)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/sphere.png" align="middle" width="400px"/>
        <figcaption>Rendered image (wall-e)</figcaption>
      </td>
      <td>
        <img src="images/sphere_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (wall-e)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
